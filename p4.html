<!DOCTYPE html>
<html>
<head>
	<title>Artificial intelligence
</title>
</head>
<body>
	<h1>Artificial intelligence
</h1>
	<h2>links</h2>
	<ul>
  <li><a href="index.html">main page</a></li>
  <li><a href="p1.html">Artificial intelligence Introduction</a></li>
  <li><a href="p2.html">Artificial intelligence table</a></li>
   <li><a href="p3.html">image</a></li>
  <li><a href="p4.html">Artificial intelligence applications</a></li>
</ul>
As ML applications are becoming ever more pervasive, fully-trained systems are made increasingly available to a wide public, allowing end-users to submit queries with their own data, and to efficiently retrieve results. With increasingly sophisticated such services, a new challenge is how to scale up to evergrowing user bases. In this paper, we present a distributed architecture that could be exploited to parallelize a typical ML system pipeline. We start from a case study consisting of a text mining service and then discuss how the proposed method can be generalized to many similar applications. We demonstrate the significance of the computational gain boosted by the distributed architecture by way of an extensive experimental evaluation. 


</body>
</html>